## ğŸŒ OSIVEX Â· Global News Intelligence & AI RAG System

OSIVEX (Open Source Intelligence Visualization & Exploration) is an AI-driven intelligence and analytics platform that collects, processes, summarizes, and analyzes open-source geopolitical data.
The system automatically scrapes international media sources (India, China, Russia), translates articles, summarizes content, classifies relevance, stores structured data, builds FAISS indexes, and performs advanced LangChain RAG retrieval through a modern Streamlit interface.

OSIVEX is designed as a fully functional AI analytics product, ideal for portfolio demonstration, interview scenarios, and real-world OSINT applications.

### ğŸ§  How OSIVEX Works
```
News â†’ Clean Text â†’ NLP Pipeline â†’ FAISS Embeddings â†’ LangChain RAG â†’ Streamlit UI

1. Parsing Layer

âœ… Crawl newest articles

âœ… Extract text & metadata

âœ… Translate via GPT

âœ… Summarize content

âœ… roduce normalized article objects

2. NLP Processing Layer

âœ… YAKE keyword extraction

âœ… RoBERTa relevance classification

3. Storage Layer

âœ… Save data to JSON

âœ… Optional PostgreSQL persistence

4. Vector Indexing (FAISS)

âœ… Build multilingual & English summary indexes

5. Retrieval Layer (LangChain)

âœ… Smart Mode: lightweight contextual retrieval

âœ… Deep Mode: multi-hop reasoning with larger context

6. Final Output

âœ… Clean, structured summary

âœ… References with source URLs

âœ… Interactive display in Streamlit dashboard

```
### ğŸš€ Live Demo
```

streamlit run osivex_app.py

```
### ğŸ§© Features
```
Data Ingestion

âœ… Fetches latest geopolitical news (Russia, China, Brazil, India â€” extensible)
âœ… Unified parser architecture for adding new countries/sources

AI Processing

âœ… GPT translation and summarization
âœ… YAKE keyword extraction
âœ… RoBERTa relevance filtering
âœ… Configurable Smart/Deep retrieval modes

Storage & Indexing

âœ…JSON + optional PostgreSQL support
âœ…FAISS vector store (multi-language + summaries)
âœ… Automatic embedding refresh

Streamlit Dashboard

âœ… Full-text semantic search
âœ… Multi-language answers
âœ… FAISS index selector
âœ…Debug console & RAG internals
âœ… Source viewer with direct article links



```
### ğŸ—  Architecture Overview (End-to-End Data Flow)
```

User â†’ run_all_parsers.py
        â†“
[Parsing Layer]
   â”œâ”€ Extract article URLs (Multi-source parser registry)
   â”œâ”€ Fetch full text & metadata
   â””â”€ Normalize article objects
      â†“
[NLP Pipeline]
   â”œâ”€ Translation (GPT)
   â”œâ”€ Summarization (GPT)
   â”œâ”€ Keyword extraction (YAKE)
   â””â”€ Relevance filtering (RoBERTa)
      â†“
[Storage Layer]
   â”œâ”€ Save to JSON
   â””â”€ Insert into PostgreSQL (optional)
      â†“
[Vector Indexing]
   â””â”€ Build FAISS index from multilingual embeddings
      â†“
[RAG Layer]
   â”œâ”€ Smart mode (light retrieval)
   â””â”€ Deep mode (multi-hop)
      â†“
[UI Output â€“ Streamlit]
   â”œâ”€ Final answer
   â”œâ”€ Source links
   â””â”€ Search history



```
### ğŸ“‚ Project Structure
```

osivex/
â”‚
â”œâ”€ data/                      # Parsed & processed JSON articles
â”œâ”€ logs/                      # Parser execution logs
â”‚
â”œâ”€ parsers/                   # Country-specific news parsers
â”‚   â”œâ”€ brazil/                   
â”‚   â”œâ”€ china/                  
â”‚   â””â”€ russia/           
â”‚
â”œâ”€ chains/                    # LangChain RAG pipelines
â”‚   â”œâ”€ pipeline_rag.py        #   Smart & Deep retrieval flows
â”‚   â”œâ”€ retrieve_faiss.py      #   FAISS retriever logic
â”‚   â””â”€ smart_mode.py          #   Lightweight retrieval mode
â”‚
â”œâ”€ faiss_index/               # Local FAISS vector stores
â”‚
â”œâ”€ streamlit/                 # UI components
â”‚   â”œâ”€ osivex_app.py          #   Main dashboard (v3)
â”‚   â””â”€ osivex_app_legacy.py   #   Previous version (reference)
â”‚
â”œâ”€ run_all_parsers.py         # Master script: RIA + TASS + Kommersant
â”œâ”€ config.py                  # Global settings (toggles, env config)
â”œâ”€ article_helpers.py         # Text cleaning, formatting, metadata utils
â”œâ”€ requirements.txt           # Python dependencies
â”‚
â””â”€ README.md                  # Documentation (this file)


```
## ğŸ—„ï¸ Database (PostgreSQL) Integration
```
OSIVEX includes optional PostgreSQL storage for production-level data persistence.
Every parsed article â€” including original text, translated content, summaries,
keywords, metadata, and relevance scores â€” is stored in a normalized schema.

```
â° Automated Ingestion (Cron Jobs)
```
OSIVEX runs fully unattended on a remote Ubuntu server.

A daily cron schedule triggers run_all_parsers.py twice a day:

ğŸ•• 06:00 â€” morning collection

ğŸ•• 18:00 â€” evening collection

Each automated run:

âœ… fetches fresh articles from all configured sources,

âœ… processes them through the NLP pipeline (translation, summarization, relevance),

âœ… inserts normalized records into PostgreSQL (articles table),

âœ… writes cron output & errors into:
/home/ubuntu/osivex/logs/parsers_cron.log


```
### Stored Fields
```
| Column              | Description                                     |
|---------------------|-------------------------------------------------|
| source              | News provider (RIA, TASS, Kommersant, etc.)     |
| country             | Country of origin                               |
| title               | Original article title                          |
| url                 | Source link                                     |
| published_date      | Article publication date                        |
| original_content    | Extracted raw text                              |
| translated_content  | GPT-translated article                          |
| summary             | GPT summary                                     |
| keywords            | YAKE keyword extraction                         |
| relevance_score     | RoBERTa relevance classification                |
| collected_at        | Timestamp of OSIVEX ingestion                   |


```
### Environment Variables (.env)
```
DB_HOST=your_host
DB_PORT=5432
DB_NAME=osivex
DB_USER=postgres
DB_PASS=your_password

```
### Notes

```
- Database support is **optional** (JSON-only mode still works).
- Streamlit dashboard reads articles directly from PostgreSQL.
- Future analytics dashboards will run SQL-based queries.


```
### ğŸš€ Getting Started

```
1ï¸âƒ£ Install dependencies:
pip install -r requirements.txt

2ï¸âƒ£ Create a .env file and add your OpenAI key
(Add your OpenAI / HuggingFace keys used by the RAG pipeline)
OPENAI_API_KEY=your_key_here
HUGGINGFACEHUB_API_TOKEN=<your_hf_token>

3ï¸âƒ£ Run parsers
(Collect news, translate/summarize, and save JSON dataset)
python run_all_parsers.py

4ï¸âƒ£ Launch the RAG dashboard
(Streamlit UI for querying BRICS/SCO geopolitics)
streamlit run osivex_app.py

```
### âš™ï¸ Configuration (config.py)
```

| Toggle                            | Description                                 |
|-----------------------------------|---------------------------------------------|
| `DEBUG_MODE`, `MAX_ARTICLES`      | Limit article count for quick testing       |
| `USE_GPT`                         | Enable GPT translation & summarization      |
| `USE_FAISS`                       | Toggle FAISS vector index for RAG           |
| `SMART_MODE`, `DEEP_MODE`         | Control retrieval depth (Light vs Deep)     |
| `LANGUAGE`, `TEMPERATURE`         | Tune GPT response settings                  |
| `ROBERTA_FILTER`                  | Enable XLM-RoBERTa relevance classification |
| `ROBERTA_VERBOSE_LOGS`            | Show detailed relevance-filter logs         |

```

### ğŸ“Š Example Logs

```text
2025-08-14 15:02:07 â€” INFO â€” âœ” Article saved
2025-08-14 15:02:08 â€” INFO â€” Filtered and saved 1 out of 10 articles for keyword "SCO"
2025-08-14 15:02:08 â€” INFO â€” Saved to data/kommersant_sco_today_en.json
2025-08-14 15:02:08 â€” INFO â€” >>> Kommersant parser completed.

=== Per-parser durations ===
RIA 5.45 s OK
TASS 3.41 s OK
Kommersant 22.38 s OK

=== All parsers finished at 2025-08-14 15:02:08 ===
Total duration: 00:00:31


```
### ğŸ—‚ Example JSON Output


```json

{
  "source": "TASS",
  "keyword": "BRICS",
  "collected_at": "2025-11-04T15:02:08Z",
  "vectorized": true,
  "articles": [
    {
      "title": "BRICS leaders meet in Kazan",
      "url": "https://tass.ru/...",
      "date": "2025-11-04",
      "summary": "Discussion on expanding trade within BRICS.",
      "embedding_id": "vec_00123",
      "relevance": 0.92,
      "keywords": ["BRICS", "trade", "Kazan"]
    }
  ]
}
```

### ğŸ“… Roadmap (Augâ€“Dec 2025)
```
Phase	   Goal
Phase 1	   Refactor RAG pipeline (LangChain LCEL)
Phase 2	   Add analytics dashboard (Streamlit visuals)
Phase 3	   Automate FAISS embedding updates
Phase 4	   Deploy FastAPI endpoint for external RAG queries

```
### ğŸ§  Technologies Used
```

â€¢ Python 3.11+
â€¢ BeautifulSoup + Requests (web-scraping)
â€¢ LangChain (RAG orchestration)
â€¢ FAISS (vector indexing)
â€¢ OpenAI GPT API (translation & summarization)
â€¢ RoBERTa (relevance classification)
â€¢ YAKE (keyword extraction)
â€¢ Streamlit (front-end dashboard)
â€¢ PostgreSQL + JSON (storage and persistence)

```
### ğŸ“„ License (Private Use Only)
```
This repository is part of the OSIVEX AI Research Suite and is provided solely for
private research, portfolio demonstration, and educational purposes.

Â© 2025 Artiom Kisliakov  
Project: OSIVEX v6  
Modules included: AI RAG, NLP Processing, Streamlit Visualization  
Edition: Internal Research Release (2025â€“2026)

All rights reserved.  
Commercial use, redistribution, copying, or integration into external products is strictly prohibited
without prior written permission from the author.
